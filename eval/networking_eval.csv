# Chapter 1 – Introduction to Computer Networks and the Internet
What are the main components of the Internet’s structure?,,,"The Internet comprises end systems (hosts), communication links, packet switches/routers, and standardized protocols that govern data exchange. End systems run applications and originate/terminate packets; links (fiber, copper, wireless) offer bandwidth with associated propagation and transmission delays. Routers implement the data plane (forwarding) and participate in control-plane protocols to learn routes. Protocols across layers (e.g., HTTP, TCP/UDP, IP, Ethernet/Wi-Fi) ensure interoperability among heterogeneous networks. The Internet is often described as a network of networks, where autonomous systems interconnect using BGP policies."
Explain the difference between circuit switching and packet switching.,,,"Circuit switching reserves end-to-end resources (bandwidth, buffer) for the session, providing predictable performance and constant bit rate but with low utilization for bursty traffic. Packet switching statistically multiplexes flows by splitting data into packets that share links on demand, achieving high utilization and elasticity at the cost of variable delay and potential loss. Circuit switching has call setup and can guarantee QoS; packet switching needs congestion control and buffering to manage contention. Internet design favors packet switching because most applications are bursty and benefit from resource sharing. Modern networks may combine both ideas (e.g., MPLS/DetNet) for QoS."
What factors contribute to network delay and throughput?,,,"A packet experiences processing delay (header checks), queuing delay (waiting behind other packets), transmission delay (L/R for L bits over R bps), and propagation delay (distance/speed in medium). Queuing delay grows nonlinearly as utilization approaches 1, making congestion particularly harmful. Throughput is constrained by the slowest path segment (bottleneck link) and by end-host congestion control behavior. Variability in delay (jitter) arises from dynamic queuing and link-layer retransmissions, impacting real-time apps. Performance engineering balances traffic shaping, AQM/ECN, and adequate capacity provisioning."
How do protocols and layers contribute to modular network design?,,,"Layering decomposes communication into modules with well-defined service interfaces: application, transport, network, and link/physical. Each layer hides implementation details and exposes an abstract service (e.g., TCP offers reliable byte stream to applications, independent of routing and link technology). Protocol stacks enable independent evolution (e.g., Wi-Fi upgrades don’t break HTTP), reuse (multiple apps reuse TCP), and interoperability across vendors. Encapsulation carries higher-layer payloads inside lower-layer headers, and demultiplexing (e.g., port numbers, protocol fields) directs packets to the correct module. Clear separation also enables diagnostics and security controls at multiple layers."

# Chapter 2 – Application Layer
What are the main characteristics of the client-server model?,,,"Clients initiate requests and are typically ephemeral; servers are persistent, addressable services that accept incoming requests concurrently (possibly via threads/process pools or async I/O). The model centralizes control, simplifies state management, and enables consistent security policies, but can be a scalability hotspot without load balancing or CDNs. DNS names map to server IPs, often anycasted or behind load balancers. TLS terminates at servers (or edge proxies) to provide confidentiality and integrity. Modern deployments use autoscaling groups and caching tiers to meet variable demand."
How does DNS resolve a domain name into an IP address?,,,"A stub resolver queries its local recursive resolver, which may answer from cache or perform iterative queries: root → TLD → authoritative servers. The resolver follows NS referrals and obtains the final A/AAAA records, validating DNSSEC if enabled via DS/DNSKEY/RRSIG chains. Answers and negative results are cached with TTLs to reduce latency and load. Additional records (CNAME, MX, SRV, TXT) support indirection, mail routing, service discovery, and policy. DNS performance and resilience rely on distributed anycasted authorities, redundancy, and proper caching behavior."
Explain the difference between HTTP persistent and non-persistent connections.,,,"Non-persistent HTTP/1.0 opens one TCP connection per object, incurring multiple RTTs and slow-start penalties per object; this amplifies latency for pages with many resources. Persistent connections (HTTP/1.1 keep-alive) amortize handshake cost across many requests and enable pipelining (limited in practice) or, with HTTP/2/3, full multiplexing and header compression. Persistent transport also interacts better with TCP congestion control by maintaining a warmed congestion window. Today, HTTP/2 over TLS/TCP and HTTP/3 over QUIC are standard for efficient, secure, multiplexed delivery."
Calculate the total response time for a non-persistent HTTP session that fetches one HTML file and three images, each requiring 2 RTTs (Round Trip Times).,,,"Under non-persistent HTTP/1.0 (serial connections), each object costs roughly 2 RTTs (TCP handshake + request/response). One HTML (2 RTTs) plus three images (3×2 RTTs) totals 8 RTTs before considering transmission time. If the browser opens up to, say, 6 parallel connections, the effective wall-clock time can drop, but slow-start and congestion can still limit throughput. Persistent HTTP or HTTP/2/3 would reduce connection setup overhead by reusing one transport and multiplexing requests."

# Chapter 3 – Transport Layer
What is the purpose of TCP’s congestion control mechanism?,,,"TCP adapts its sending rate to available network capacity to prevent persistent queue buildup and collapse. It increases the congestion window (cwnd) on positive feedback (ACKs) and decreases it on inferred congestion (loss/ECN), implementing additive-increase/multiplicative-decrease (AIMD). Algorithms include slow start (exponential growth), congestion avoidance (linear growth), fast retransmit/recovery (react to triple-duplicate ACKs), and modern variants (CUBIC, BBR). Proper control yields fairness among flows sharing a bottleneck and stabilizes queues to keep latency acceptable. ECN and AQM (e.g., CoDel, PIE) provide early congestion signals."
Explain how TCP provides reliable data transfer.,,,"TCP numbers bytes in a stream and acknowledges cumulative receipt; timeouts or duplicate ACKs signal loss and trigger retransmission. Sliding windows allow multiple in-flight segments, balancing throughput and latency. Selective acknowledgments (SACK) let the sender retransmit only missing data, improving recovery in burst loss. Checksums detect corruption; ordered delivery at the receiver reassembles the byte stream despite reordering. Flow control (rwnd) protects receivers from overrun, while congestion control protects the network fabric."
Compare UDP and TCP in terms of reliability, latency, and use cases.,,,"UDP provides best-effort, message-oriented delivery with minimal header overhead and no connection setup, favoring low latency and application-level control (e.g., real-time media, gaming, DNS). TCP offers reliable, ordered, congestion-controlled delivery with connection semantics, suitable for bulk transfer and transactional traffic (web, email). UDP applications often implement their own reliability, FEC, or congestion signaling (e.g., QUIC’s congestion control and reliability at the application layer). Choice depends on tolerance for loss, latency sensitivity, and required delivery guarantees."
A TCP connection’s congestion window increases from 10 to 20 MSS in 1 second. If MSS = 1 KB, estimate the throughput in kbps.,,,"Throughput approximates the sending rate of in-flight data per RTT epoch; with cwnd reaching 20 KB over 1 second, average rate ≈ 20 KB/s. Converting to bits: 20 KB/s × 8 = 160 kbps. This back-of-the-envelope ignores ACK compression, path RTT variations, loss events, and application think time; in practice, sustained throughput depends on RTT (BDP), loss probability p (≈1/√p for AIMD), and receiver window."

# Chapter 4 – Network Layer: Data Plane
What is the main function of the data plane in the network layer?,,,"The data plane implements fast per-packet forwarding based on headers and a forwarding information base (FIB). It applies longest-prefix match for IP, decrements TTL/Hop Limit, and may perform NAT, ACL checks, and queuing. Implementations range from software stacks to ASIC pipelines and programmable data planes (P4). The control plane populates the FIB (e.g., via OSPF/BGP/SDN), while the data plane executes at line rate with strict timing constraints. Separation enables high throughput and flexible policy updates."
How does a router use a forwarding table to send packets?,,,"The router extracts the destination IP, performs longest-prefix match against the FIB to identify the next hop and egress interface, and updates per-packet fields (e.g., TTL, checksum). If ARP/ND is needed, it resolves next-hop MAC to forward on L2. Default routes catch traffic not matching more specific prefixes. Fast paths (TCAMs, FIB caches) accelerate lookups, while control CPU handles exceptions. Multi-path (ECMP) may load balance across equal-cost routes."
Explain the concept of datagram fragmentation in IPv4.,,,"If a packet exceeds a link’s MTU, IPv4 routers fragment it into smaller pieces carrying the same Identification and appropriate Fragment Offset and MF (More Fragments) bits. The destination host reassembles fragments into the original datagram; intermediate routers do not reassemble. Fragmentation increases overhead and loss sensitivity (loss of one fragment drops the whole datagram). Path MTU discovery attempts to avoid fragmentation by probing with DF set and adjusting size based on ICMP feedback."
A 4500-byte IPv4 packet must cross a link with MTU = 1500 bytes. How many fragments are created?,,,"Each fragment needs a 20-byte IPv4 header; payload per fragment must be a multiple of 8 bytes. Max payload per fragment = 1500 − 20 = 1480 bytes. 4500-byte total includes the initial IP header, so payload ≈ 4480 bytes; 4480/1480 = 3.027 → three fragments. Two fragments carry 1480-byte payloads; the last carries the remaining 1520-byte payload split as 1480 + 40? Careful: after two full payloads (2960), remaining payload is 1520 → split into one final fragment of 1520 (valid because 1520 is divisible by 8). Thus 3 fragments total (each with 20B headers), acknowledging implementations may vary in exact byte accounting but the count is three."

# Chapter 5 – Network Layer: Control Plane
What are the main goals of routing algorithms?,,,"Routing seeks loop-free, low-cost paths that adapt to topology or load changes while scaling to large networks. Metrics can represent hop count, latency, loss, or policy cost. Algorithms must converge quickly to avoid transient loops and blackholes, and withstand failures via redundancy. Trade-offs include control overhead, state size, and responsiveness vs stability (flap damping). In interdomain routing, policy and business relationships strongly influence path selection."
Compare link-state and distance-vector routing algorithms.,,,"Link-state (e.g., OSPF, IS-IS) floods local link metrics to all routers; each runs Dijkstra to compute shortest paths, converging quickly with a global view at the cost of more state and LS database synchronization. Distance-vector (e.g., RIP) exchanges only distance estimates with neighbors and uses Bellman-Ford; it has lower overhead but slower convergence and count-to-infinity issues (mitigated by split horizon/poison reverse). In practice, link-state is used intra-domain for scale and speed; BGP (a path-vector variant) governs interdomain policy."
What is Software Defined Networking (SDN) and how does it differ from traditional networking?,,,"SDN decouples the control plane from the data plane, placing decision logic in a logically centralized controller that programs switches via southbound APIs (e.g., OpenFlow, P4Runtime). This enables global network views, rapid policy changes, and automation (traffic engineering, access control, service chaining). Traditional networks embed control locally in each device and rely on distributed protocols, making coherent policy harder. SDN can coexist with distributed protocols and is often used in datacenters and WANs for fine-grained control."
If a network uses OSPF with five routers and 10 links, how many link-state advertisements (LSAs) are initially flooded?,,,"Each router originates an LSA describing its adjacencies and link metrics; these LSAs are flooded reliably throughout the area. With five routers, initially five LSAs circulate (not 10), though LSAs will be re-originated upon changes (e.g., link up/down). Additional LSA types (network LSAs, summaries) may appear depending on multi-access networks and area design, but base accounting begins with one router-LSA per router."

# Chapter 6 – Link Layer and LANs
What is the role of the link layer in data transmission?,,,"The link layer encapsulates network-layer packets into frames and provides node-to-node delivery across a single hop. It handles framing, addressing (MAC), error detection (CRC), and sometimes error recovery/flow control (e.g., Wi-Fi ARQ, PAUSE frames). Media access control governs how multiple nodes share a medium (CSMA/CA in Wi-Fi, switched full-duplex in Ethernet). Performance features include interframe gaps, MTU constraints, and QoS markings (802.1p)."
How does Ethernet handle collisions in shared media?,,,"Classic shared-bus Ethernet used CSMA/CD: nodes sense the carrier, transmit if idle, and detect collisions via signal energy; upon collision, they jam the channel and back off using binary exponential backoff. Switches and full-duplex links have eliminated collisions in modern Ethernet by dedicating a collision-free segment per port. Nonetheless, Ethernet retains frame structure, FCS, and autonegotiation; congestion now manifests as buffer drops, not collisions."
What are the differences between MAC and IP addresses?,,,"MAC addresses (48-bit EUI-48, often written as hex pairs) identify network interfaces at Layer-2 and are flat (non-hierarchical). IP addresses (v4/v6) are Layer-3 and hierarchical, enabling scalable routing across subnets. ARP (IPv4) or Neighbor Discovery (IPv6) maps IP to MAC for local delivery. MACs are link-local and don’t traverse routers; IPs change across subnets or with mobility, whereas MACs typically remain tied to the NIC."
A 100-Mbps Ethernet link transmits 1500-byte frames. What is the theoretical maximum throughput in MB/s?,,,"Raw capacity is 100 Mb/s ÷ 8 = 12.5 MB/s. Sending 1500-byte payloads yields 12,000 bits per frame excluding L2/L3/L4 overheads; achievable throughput is lower due to headers (Ethernet/IP/TCP), interframe gap (12 bytes) and preamble/SFD (8 bytes). Jumbo frames reduce header amortization and interrupt overhead, increasing effective throughput and efficiency."

# Chapter 7 – Wireless and Mobile Networks
What are the main differences between wired and wireless links?,,,"Wireless links suffer from path loss, multipath fading, interference, and shared medium contention; error rates and latency variance are higher than wired. Wi-Fi uses CSMA/CA (with RTS/CTS) to reduce collisions due to hidden terminals, while wired switched Ethernet avoids collisions. Mobility introduces handoffs and variable link quality, requiring adaptive rate control and power management. Link-layer retransmissions and coding partially hide losses from upper layers but can increase delay."
Explain the purpose of handoff in mobile networks.,,,"Handoff transfers an ongoing connection from one base station/AP to another as the user moves, preserving session continuity and QoS. Triggers include signal strength thresholds or network load; handoffs can be hard (break-before-make) or soft (make-before-break). In cellular systems, the core coordinates mobility and updates location/state; in Wi-Fi, the client often initiates scanning and association, with 802.11r enabling fast transitions. Effective handoff minimizes packet loss and interruption."
What factors influence signal-to-noise ratio (SNR) in wireless communication?,,,"SNR is determined by transmit power, antenna gains, path loss (∝ distance and frequency), shadowing, fading, and interference from other transmitters. Higher SNR enables higher modulation and coding schemes (MCS), boosting throughput at a cost of reduced range. Environmental factors (walls, human bodies, weather) and channel bandwidth also matter. Adaptive modulation and power control dynamically balance throughput and reliability."
A Wi-Fi access point transmits at 100 mW. If path loss is 40 dB, what is the received power in mW?,,,"Transmit power 100 mW corresponds to +20 dBm (10·log10(100)). Received power in dBm = 20 − 40 = −20 dBm. Converting back to mW: 10^(−20/10) ≈ 0.01 mW. In practice, antenna gains and fading cause further variation; sensitivity thresholds dictate achievable data rates at this power."

# Chapter 8 – Network Security
What is the purpose of cryptography in network security?,,,"Cryptography provides confidentiality (encryption), integrity (MACs/hashes), authentication (proving identity), and non-repudiation (signatures). Protocols like TLS establish secure channels using key exchange (e.g., ECDHE), certificates, and symmetric bulk encryption (AES-GCM/ChaCha20-Poly1305). Perfect forward secrecy ensures past sessions remain secure even if long-term keys are compromised. Sound cryptography must be paired with robust implementations and key management."
Explain the difference between symmetric and asymmetric encryption.,,,"Symmetric ciphers use one shared key for encryption and decryption (fast and suitable for bulk data), whereas asymmetric cryptography uses public/private key pairs enabling key exchange and digital signatures. Asymmetric operations are slower and used to bootstrap symmetric session keys (e.g., in TLS handshakes). Security relies on hardness assumptions (e.g., discrete log, factoring). Hybrid designs combine both: public-key for auth/key exchange, symmetric for data."
What are digital certificates and why are they important?,,,"Digital certificates bind a subject’s identity to a public key and are signed by a trusted Certificate Authority (CA). Clients verify certificate chains to a trusted root store and check revocation/validity before trusting a server. Certificates enable authenticated key exchange in TLS, preventing MITM attacks. Proper issuance, transparency logs, and rotation policies are critical to ecosystem security."
If a message digest using SHA-256 produces a 256-bit hash, how many possible outputs exist?,,,"SHA-256 outputs a 256-bit value, yielding 2^256 ≈ 1.16×10^77 possible hashes. The birthday bound for collisions is roughly 2^(256/2) = 2^128 operations, which is computationally infeasible with current technology. Preimage resistance similarly requires ≈2^256 work. Thus, SHA-256 provides a very large security margin for integrity checks and commitments."

# Chapter 9 – Multimedia Networking
What is Quality of Service (QoS) and why is it important for multimedia?,,,"QoS mechanisms manage bandwidth, delay, jitter, and loss to meet application requirements (e.g., VoIP, video streaming). Tools include admission control, traffic classification, queuing disciplines (WFQ/priority), shaping/policing, and congestion signaling. Without QoS, bursts or competing flows can cause bufferbloat and playback stalls. Modern networks combine over-provisioning with AQM/ECN and application-layer adaptation (ABR). End-to-end QoS often requires coordination across domains."
How do buffering and playout delay improve streaming performance?,,,"A receiver buffer accumulates media before playback to absorb network jitter; a playout delay schedules frames at a steady cadence even if packets arrive irregularly. Larger buffers reduce rebuffer events but increase start-up latency; adaptive bitrate (ABR) algorithms trade bitrate for fewer stalls. Key parameters include buffer size, rebuffer thresholds, and target latency (live vs on-demand). Combined with forward error correction or retransmissions, buffering stabilizes user experience."
Explain the difference between RTP and RTCP.,,,"RTP carries real-time media payloads with sequence numbers and timestamps for ordering and synchronization; it rides over UDP to minimize latency and allow application-specific recovery. RTCP is a companion control protocol that periodically reports reception quality (loss, jitter, RTT) and conveys sender/receiver reports for synchronization (e.g., audio/video lip-sync). Together they enable adaptive media transmission and monitoring without imposing reliability overhead."
If a video stream requires 5 Mbps and the network link supports 10 Mbps, what is the maximum number of simultaneous identical streams?,,,"Ignoring overheads, 10 Mbps / 5 Mbps = 2 streams. In practice, protocol overhead (IP/UDP/RTP), encryption, and other traffic reduce effective capacity; safe planning includes a margin (e.g., 20–30%). Adaptive bitrate streaming may downshift quality to fit more sessions, but QoE targets (stall rate, resolution) should dictate admission control."
